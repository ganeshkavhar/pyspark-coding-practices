{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9ff647-bbac-4fed-843c-d60e4b5551bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed String: !dlroW olleH\n"
     ]
    }
   ],
   "source": [
    "def reverse_string(input_string):\n",
    "    return input_string[::-1]\n",
    "\n",
    "# Test the function\n",
    "input_str = \"Hello World!\"\n",
    "reversed_str = reverse_string(input_str)\n",
    "print(\"Reversed String:\", reversed_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb4517bd-cca4-4bbf-8d24-5984f37de2a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Pyspark UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c086fb-b13d-4bf9-86aa-2c66372f259c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n|input_string|reversed_string|\n+------------+---------------+\n|Hello World!|!dlroW olleH   |\n+------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ReverseString\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Hello World!\",)]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, [\"input_string\"])\n",
    "\n",
    "# Define a UDF (User Defined Function) to reverse a string\n",
    "@udf(StringType())\n",
    "def reverse_string_udf(input_string):\n",
    "    return input_string[::-1]\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "df = df.withColumn(\"reversed_string\", reverse_string_udf(df[\"input_string\"]))\n",
    "\n",
    "# Show the result\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f576086-717f-40a2-96f5-5bcf424318a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pyspark UDF to check number even_odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73df1dac-d934-4a7b-8ea0-fbee8a1ef1be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n|number|even_odd|\n+------+--------+\n|     1|     Odd|\n|     2|    Even|\n|     3|     Odd|\n|     4|    Even|\n|     5|     Odd|\n+------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"EvenOddUDFExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1,), (2,), (3,), (4,), (5,)]\n",
    "df = spark.createDataFrame(data, [\"number\"])\n",
    "\n",
    "# Define UDF to check if a number is even or odd\n",
    "def check_even_odd(number):\n",
    "    if number % 2 == 0:\n",
    "        return \"Even\"\n",
    "    else:\n",
    "        return \"Odd\"\n",
    "\n",
    "# Register UDF\n",
    "even_odd_udf = udf(check_even_odd, StringType())\n",
    "\n",
    "# Apply UDF to DataFrame\n",
    "df = df.withColumn(\"even_odd\", even_odd_udf(df[\"number\"]))\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b724003-ba12-4578-8911-e16d083ec393",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pyspark UDF to check string palindrome or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d219d81b-548a-4db4-9b21-c7fa9ab55352",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n| word| is_palindrome|\n+-----+--------------+\n|radar|    Palindrome|\n|hello|Not Palindrome|\n|level|    Palindrome|\n|world|Not Palindrome|\n+-----+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"PalindromeUDFExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"radar\",), (\"hello\",), (\"level\",), (\"world\",)]\n",
    "df = spark.createDataFrame(data, [\"word\"])\n",
    "\n",
    "# Define function to check if a string is palindrome\n",
    "def check_palindrome(word):\n",
    "    return \"Palindrome\" if word == word[::-1] else \"Not Palindrome\"\n",
    "\n",
    "# Register UDF\n",
    "palindrome_udf = udf(check_palindrome, StringType())\n",
    "\n",
    "# Apply UDF to DataFrame\n",
    "df = df.withColumn(\"is_palindrome\", palindrome_udf(df[\"word\"]))\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ba0e6a4-13f1-4804-9d81-46b67d61bbaa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pyspark UDF to reverse a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6b36f7-90ab-4eae-8205-b38dfa3631d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n| list_col|reversed_list|\n+---------+-------------+\n|[1, 2, 3]|    [3, 2, 1]|\n|[4, 5, 6]|    [6, 5, 4]|\n|[7, 8, 9]|    [9, 8, 7]|\n+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReverseListUDFExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [([1, 2, 3],), ([4, 5, 6],), ([7, 8, 9],)]\n",
    "df = spark.createDataFrame(data, [\"list_col\"])\n",
    "\n",
    "# Define function to reverse a list\n",
    "def reverse_list(lst):\n",
    "    return lst[::-1]\n",
    "\n",
    "# Register UDF\n",
    "reverse_list_udf = udf(reverse_list, ArrayType(StringType()))\n",
    "\n",
    "# Apply UDF to DataFrame\n",
    "df = df.withColumn(\"reversed_list\", reverse_list_udf(df[\"list_col\"]))\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Best Code Practs",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
